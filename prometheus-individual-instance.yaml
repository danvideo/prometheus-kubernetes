apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-k8s-config
data:
  prometheus.yaml: |
    global:
      scrape_interval: 60s
      scrape_timeout: 60s
      evaluation_interval: 60s

      # Attach these labels to any time series or alerts when communicating with
      # external systems (federation, remote storage, Alertmanager).
      external_labels:
        monitor: 'prometheus-k8s-monitor'

    # Rule files specifies a list of globs. Rules and alerts are read from
    # all matching files.
    rule_files:
      - '/etc/prometheus/rules/*.rules'

    # A scrape configuration containing exactly one endpoint to scrape:
    # Here it's Prometheus itself.
    scrape_configs:
      # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
      - job_name: 'prometheus'

        # Override the global default and scrape targets from this job every 5 seconds.
        scrape_interval: 5s

        static_configs:
          - targets: ['localhost:9090']
        relabel_configs:
        - target_label: colo
          action: replace
          replacement: %COLO%

      - job_name: kubernetes-apiservers
        scrape_interval: 30s
        scrape_timeout: 5s
        metrics_path: /metrics
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        file_sd_configs:
        - files: ["/etc/prometheus/targets/apiserver-%ENV_K8S%%COLO%.json"]
        relabel_configs:
        - target_label: colo
          action: replace
          replacement: %COLO%

    # Scrape Scheduler
      - job_name: 'kubernetes-scheduler'
        scrape_interval: 30s
        scrape_timeout: 5s
        scheme: https
        metrics_path: /metrics
        params:
          port: ['10251']
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        file_sd_configs:
        - files: ["/etc/prometheus/targets/scheduler-%ENV_K8S%%COLO%.json"]
        relabel_configs:
        - target_label: colo
          action: replace
          replacement: %COLO%

    # Scrape Controller
      - job_name: 'kubernetes-controller'
        scrape_interval: 30s
        scrape_timeout: 5s
        scheme: https
        metrics_path: /metrics
        params:
          port: ['10252']
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        file_sd_configs:
        - files: ["/etc/prometheus/targets/controller-%ENV_K8S%%COLO%.json"]
        relabel_configs:
        - target_label: colo
          action: replace
          replacement: %COLO%

    # Scrape ETCD servers
      - job_name: 'kubernetes-etcd'
        scrape_interval: 30s
        scrape_timeout: 5s
        scheme: https
        metrics_path: /metrics
        params:
          port: ['2379']
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        file_sd_configs:
        - files: ["/etc/prometheus/targets/etcd-%ENV_K8S%%COLO%.json"]
        relabel_configs:
        - target_label: colo
          action: replace
          replacement: %COLO%

    # Scrape config for nodes (kubelet).
    #
    # Rather than connecting directly to the node, the scrape is proxied though the
    # Kubernetes apiserver.  This means it will work if Prometheus is running out of
    # cluster, or can't connect to nodes for some other reason (e.g. because of
    # firewalling).
      - job_name: 'kubernetes-nodes'

        # Default to scraping over https. If required, just disable this or change to
        # `http`.
        scheme: https

        # This TLS & bearer token file config is used to connect to the actual scrape
        # endpoints for cluster components. This is separate to discovery auth
        # configuration because discovery & scraping are two separate concerns in
        # Prometheus. The discovery auth config is automatic if Prometheus runs inside
        # the cluster. Otherwise, more config options have to be provided within the
        # <kubernetes_sd_config>.
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: node

        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics
        - target_label: colo
          action: replace
          replacement: %COLO%

      # Scrape config for Kubelet cAdvisor.
      #
      # This is required for Kubernetes 1.7.3 and later, where cAdvisor metrics
      # (those whose names begin with 'container_') have been removed from the
      # Kubelet metrics endpoint.  This job scrapes the cAdvisor endpoint to
      # retrieve those metrics.
      #
      # In Kubernetes 1.7.0-1.7.2, these metrics are only exposed on the cAdvisor
      # HTTP endpoint; use "replacement: /api/v1/nodes/${1}:4194/proxy/metrics"
      # in that case (and ensure cAdvisor's HTTP server hasn't been disabled with
      # the --cadvisor-port=0 Kubelet flag).
      #
      # This job is not necessary and should be removed in Kubernetes 1.6 and
      # earlier versions, or it will cause the metrics to be scraped twice.
      - job_name: 'kubernetes-cadvisor'

        # Default to scraping over https. If required, just disable this or change to
        # `http`.
        scheme: https

        # This TLS & bearer token file config is used to connect to the actual scrape
        # endpoints for cluster components. This is separate to discovery auth
        # configuration because discovery & scraping are two separate concerns in
        # Prometheus. The discovery auth config is automatic if Prometheus runs inside
        # the cluster. Otherwise, more config options have to be provided within the
        # <kubernetes_sd_config>.
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token

        kubernetes_sd_configs:
        - role: node

        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
        - target_label: colo
          action: replace
          replacement: %COLO%


      # Scrape config for service endpoints.
      #
      # The relabeling allows the actual service scrape endpoint to be configured
      # via the following annotations:
      #
      # * `prometheus.io/scrape`: Only scrape services that have a value of `true`
      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need
      # to set this to `https` & most likely set the `tls_config` of the scrape config.
      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.
      # * `prometheus.io/port`: If the metrics are exposed on a different port to the
      # service then set this appropriately.
      - job_name: 'kubernetes-service-endpoints'

        tls_config:
          insecure_skip_verify: true

        kubernetes_sd_configs:
        - role: endpoints

        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
          action: replace
          target_label: __address__
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: replace
          target_label: kubernetes_name
        - target_label: colo
          action: replace
          replacement: %COLO%

      # Example scrape config for probing services.
      # Services backed by pods should return `200 (no body)` for `GET /probe`
      #
      # The relabeling allows the actual service scrape endpoint to be configured
      # via the following annotations:
      #
      # * `prometheus.io/probe`: Only probe services that have a value of `true`
      - job_name: 'kubernetes-services'

        scrape_interval: 60s
        scrape_timeout: 5s
        metrics_path: /healthz

        tls_config:
          insecure_skip_verify: true

        kubernetes_sd_configs:
        - role: service

        relabel_configs:
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
          action: replace
          target_label: __scheme__
          regex: (https?)
        - source_labels: [__param_target]
          target_label: instance
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          target_label: kubernetes_name

      # kubedns metrics related to dnsmasq and skydns
      - job_name: 'kube-dns'
        kubernetes_sd_configs:
        - role: endpoints
        relabel_configs:
        - source_labels: [__address__]
          action: keep
          regex: ([^:]+)(:10054|:10055)
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: keep
          regex: kube-dns
          target_label: kubernetes_name
        - target_label: colo
          action: replace
          replacement: %COLO%

      # dnsmasq
      - job_name: 'dnsmasq'
        kubernetes_sd_configs:
        - role: endpoints
        relabel_configs:
        - source_labels: [__address__]
          action: keep
          regex: ([^:]+)(:10054)
        - action: labelmap
          regex: __meta_kubernetes_service_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_service_name]
          action: keep
          regex: dnsmasq
          target_label: kubernetes_name
        - target_label: colo
          action: replace
          replacement: %COLO%


      - job_name: 'kubernetes-dashboard'
        # Override the global default
        scrape_interval: 60s
        # metrics_path defaults to '/metrics'
        # scheme defaults to 'http'.
        static_configs:
        - targets: ['kubernetes-dashboard.kube-system:4080']
        relabel_configs:
        - target_label: colo
          action: replace
          replacement: %COLO%

    alerting:
      alertmanagers:
        - kubernetes_sd_configs:
          - role: service
          relabel_configs:
          - source_labels: [__meta_kubernetes_service_name]
            action: keep
            regex: alertmanager
            target_label: kubernetes_name
